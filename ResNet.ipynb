{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Device : cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms # MNIST 데이터를 텐서 형태로 바꾸기 위해\n",
    "import torch.nn.init\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "device = None\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# 일정한 실험을 위해 랜덤 시드 고정\n",
    "seed = 777\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed) \n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 현재 디바이스가 무엇인지?\n",
    "print('Current Device : ' + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: /home/LJS/NODE\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torchvision.datasets as dsets # 이 안에 MNIST 있다\n",
    "\n",
    "if os.path.exists('MNIST'):\n",
    "    mnist_train = dsets.MNIST(root=str(os.getcwd()), train=True, transform=transforms.ToTensor(), download=False)\n",
    "    mnist_test = dsets.MNIST(root=str(os.getcwd()), train=False, transform=transforms.ToTensor(), download=False)\n",
    "else: # MNIST 데이터 다운로드\n",
    "    mnist_train = dsets.MNIST(root=str(os.getcwd()), train=True, transform=transforms.ToTensor(), download=True)\n",
    "    mnist_test = dsets.MNIST(root=str(os.getcwd()), train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "print(mnist_train)\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "train_loader = torch.utils.data.DataLoader(dataset=mnist_train, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "DataParallel                                  [100, 10]                 --\n",
       "├─ResNet: 1-1                                 [25, 10]                  686,962\n",
       "├─ResNet: 1-8                                 --                        (recursive)\n",
       "│    └─Sequential: 2-1                        [25, 1, 14, 14]           52\n",
       "│    └─Sequential: 2-41                       --                        (recursive)\n",
       "│    │    └─Conv2d: 3-1                       [25, 1, 14, 14]           50\n",
       "├─ResNet: 1-3                                 [25, 10]                  --\n",
       "├─ResNet: 1-8                                 --                        (recursive)\n",
       "│    └─Sequential: 2-3                        [25, 1, 14, 14]           --\n",
       "│    └─Sequential: 2-41                       --                        (recursive)\n",
       "│    │    └─Conv2d: 3-2                       [25, 1, 14, 14]           --\n",
       "├─ResNet: 1-5                                 [25, 10]                  --\n",
       "├─ResNet: 1-8                                 --                        (recursive)\n",
       "│    └─Sequential: 2-5                        [25, 1, 14, 14]           --\n",
       "│    └─Sequential: 2-41                       --                        (recursive)\n",
       "│    │    └─Conv2d: 3-3                       [25, 1, 14, 14]           --\n",
       "├─ResNet: 1-7                                 [25, 10]                  --\n",
       "├─ResNet: 1-8                                 --                        (recursive)\n",
       "│    └─Sequential: 2-7                        [25, 1, 14, 14]           --\n",
       "│    └─Sequential: 2-41                       --                        (recursive)\n",
       "│    │    └─Conv2d: 3-4                       [25, 1, 14, 14]           --\n",
       "│    │    └─BatchNorm2d: 3-5                  [25, 1, 14, 14]           2\n",
       "│    └─Sequential: 2-9                        [25, 1, 7, 7]             52\n",
       "│    └─Sequential: 2-43                       --                        (recursive)\n",
       "│    │    └─Conv2d: 3-6                       [25, 1, 7, 7]             50\n",
       "│    │    └─BatchNorm2d: 3-7                  [25, 1, 7, 7]             2\n",
       "│    └─Sequential: 2-11                       [25, 32, 4, 4]            28,288\n",
       "│    └─Sequential: 2-45                       --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-8                [25, 32, 4, 4]            9,728\n",
       "│    │    └─ResidualBlock: 3-54               --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-10               [25, 32, 4, 4]            18,560\n",
       "│    │    └─ResidualBlock: 3-56               --                        (recursive)\n",
       "│    └─Sequential: 2-13                       [25, 64, 2, 2]            131,712\n",
       "│    └─Sequential: 2-47                       --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-12               [25, 64, 2, 2]            57,728\n",
       "│    │    └─ResidualBlock: 3-58               --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-14               [25, 64, 2, 2]            73,984\n",
       "│    │    └─ResidualBlock: 3-60               --                        (recursive)\n",
       "│    └─Sequential: 2-15                       [25, 128, 2, 2]           525,568\n",
       "│    └─Sequential: 2-49                       --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-16               [25, 128, 2, 2]           230,144\n",
       "│    │    └─ResidualBlock: 3-62               --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-18               [25, 128, 2, 2]           295,424\n",
       "│    │    └─ResidualBlock: 3-64               --                        (recursive)\n",
       "│    └─AdaptiveAvgPool2d: 2-17                [25, 128, 1, 1]           --\n",
       "│    └─Linear: 2-18                           [25, 10]                  1,290\n",
       "│    └─Sequential: 2-41                       --                        (recursive)\n",
       "│    │    └─BatchNorm2d: 3-20                 [25, 1, 14, 14]           --\n",
       "│    └─Sequential: 2-20                       [25, 1, 7, 7]             --\n",
       "│    └─Sequential: 2-43                       --                        (recursive)\n",
       "│    │    └─Conv2d: 3-21                      [25, 1, 7, 7]             --\n",
       "│    │    └─BatchNorm2d: 3-22                 [25, 1, 7, 7]             --\n",
       "│    └─Sequential: 2-22                       [25, 32, 4, 4]            --\n",
       "│    └─Sequential: 2-45                       --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-23               [25, 32, 4, 4]            --\n",
       "│    │    └─ResidualBlock: 3-54               --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-25               [25, 32, 4, 4]            --\n",
       "│    │    └─ResidualBlock: 3-56               --                        (recursive)\n",
       "│    └─Sequential: 2-24                       [25, 64, 2, 2]            --\n",
       "│    └─Sequential: 2-47                       --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-27               [25, 64, 2, 2]            --\n",
       "│    │    └─ResidualBlock: 3-58               --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-29               [25, 64, 2, 2]            --\n",
       "│    │    └─ResidualBlock: 3-60               --                        (recursive)\n",
       "│    └─Sequential: 2-26                       [25, 128, 2, 2]           --\n",
       "│    └─Sequential: 2-49                       --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-31               [25, 128, 2, 2]           --\n",
       "│    │    └─ResidualBlock: 3-62               --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-33               [25, 128, 2, 2]           --\n",
       "│    │    └─ResidualBlock: 3-64               --                        (recursive)\n",
       "│    └─AdaptiveAvgPool2d: 2-28                [25, 128, 1, 1]           --\n",
       "│    └─Linear: 2-29                           [25, 10]                  --\n",
       "│    └─Sequential: 2-41                       --                        (recursive)\n",
       "│    │    └─BatchNorm2d: 3-35                 [25, 1, 14, 14]           --\n",
       "│    └─Sequential: 2-31                       [25, 1, 7, 7]             --\n",
       "│    └─Sequential: 2-43                       --                        (recursive)\n",
       "│    │    └─Conv2d: 3-36                      [25, 1, 7, 7]             --\n",
       "│    │    └─BatchNorm2d: 3-37                 [25, 1, 7, 7]             --\n",
       "│    └─Sequential: 2-33                       [25, 32, 4, 4]            --\n",
       "│    └─Sequential: 2-45                       --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-38               [25, 32, 4, 4]            --\n",
       "│    │    └─ResidualBlock: 3-54               --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-40               [25, 32, 4, 4]            --\n",
       "│    │    └─ResidualBlock: 3-56               --                        (recursive)\n",
       "│    └─Sequential: 2-35                       [25, 64, 2, 2]            --\n",
       "│    └─Sequential: 2-47                       --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-42               [25, 64, 2, 2]            --\n",
       "│    │    └─ResidualBlock: 3-58               --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-44               [25, 64, 2, 2]            --\n",
       "│    │    └─ResidualBlock: 3-60               --                        (recursive)\n",
       "│    └─Sequential: 2-37                       [25, 128, 2, 2]           --\n",
       "│    └─Sequential: 2-49                       --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-46               [25, 128, 2, 2]           --\n",
       "│    │    └─ResidualBlock: 3-62               --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-48               [25, 128, 2, 2]           --\n",
       "│    │    └─ResidualBlock: 3-64               --                        (recursive)\n",
       "│    └─AdaptiveAvgPool2d: 2-39                [25, 128, 1, 1]           --\n",
       "│    └─Linear: 2-40                           [25, 10]                  --\n",
       "│    └─Sequential: 2-41                       --                        (recursive)\n",
       "│    │    └─BatchNorm2d: 3-50                 [25, 1, 14, 14]           --\n",
       "│    └─Sequential: 2-42                       [25, 1, 7, 7]             --\n",
       "│    └─Sequential: 2-43                       --                        (recursive)\n",
       "│    │    └─Conv2d: 3-51                      [25, 1, 7, 7]             --\n",
       "│    │    └─BatchNorm2d: 3-52                 [25, 1, 7, 7]             --\n",
       "│    └─Sequential: 2-44                       [25, 32, 4, 4]            --\n",
       "│    └─Sequential: 2-45                       --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-53               [25, 32, 4, 4]            --\n",
       "│    │    └─ResidualBlock: 3-54               --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-55               [25, 32, 4, 4]            --\n",
       "│    │    └─ResidualBlock: 3-56               --                        (recursive)\n",
       "│    └─Sequential: 2-46                       [25, 64, 2, 2]            --\n",
       "│    └─Sequential: 2-47                       --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-57               [25, 64, 2, 2]            --\n",
       "│    │    └─ResidualBlock: 3-58               --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-59               [25, 64, 2, 2]            --\n",
       "│    │    └─ResidualBlock: 3-60               --                        (recursive)\n",
       "│    └─Sequential: 2-48                       [25, 128, 2, 2]           --\n",
       "│    └─Sequential: 2-49                       --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-61               [25, 128, 2, 2]           --\n",
       "│    │    └─ResidualBlock: 3-62               --                        (recursive)\n",
       "│    │    └─ResidualBlock: 3-63               [25, 128, 2, 2]           --\n",
       "│    │    └─ResidualBlock: 3-64               --                        (recursive)\n",
       "│    └─AdaptiveAvgPool2d: 2-50                [25, 128, 1, 1]           --\n",
       "│    └─Linear: 2-51                           [25, 10]                  --\n",
       "===============================================================================================\n",
       "Total params: 686,962\n",
       "Trainable params: 686,962\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 77.12\n",
       "===============================================================================================\n",
       "Input size (MB): 0.31\n",
       "Forward/backward pass size (MB): 2.66\n",
       "Params size (MB): 2.75\n",
       "Estimated Total Size (MB): 5.72\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.downsample = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.downsample(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block):\n",
    "        super().__init__()\n",
    "        self.downsample1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(num_features=1)\n",
    "        )\n",
    "        self.downsample2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(num_features=1)\n",
    "        )\n",
    "        self.in_channels = 1\n",
    "        self.layer1 = self._make_layer(block, 32, blocks=2, stride=2)\n",
    "        self.layer2 = self._make_layer(block, 64, blocks=2, stride=2)\n",
    "        self.layer3 = self._make_layer(block, 128, blocks=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(128, 10)\n",
    "        return\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks=1, stride=1):\n",
    "        layers = []\n",
    "\n",
    "        layers.append(block(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels\n",
    "\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.downsample1(x)\n",
    "        out = self.downsample2(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = nn.DataParallel(ResNet(ResidualBlock))\n",
    "summary(model, (100,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 600/600 [00:38<00:00, 15.42it/s]\n",
      "Evaluation: 100%|██████████| 100/100 [00:03<00:00, 27.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Train_Loss: 0.2951, Test_Loss: 0.1303, Test_acc: 95.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 600/600 [00:38<00:00, 15.68it/s]\n",
      "Evaluation: 100%|██████████| 100/100 [00:03<00:00, 27.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Train_Loss: 0.1266, Test_Loss: 0.0954, Test_acc: 96.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  52%|█████▎    | 315/600 [00:19<00:17, 16.04it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     27\u001b[0m \u001b[39mwith\u001b[39;00m tqdm(total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(train_loader), desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTrain\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m pbar:\n\u001b[0;32m---> 28\u001b[0m     \u001b[39mfor\u001b[39;00m x,y \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m     29\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     30\u001b[0m         train_output \u001b[39m=\u001b[39m model(x\u001b[39m.\u001b[39mto(device))\n",
      "File \u001b[0;32m~/anaconda3/envs/node/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/node/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/node/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/node/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/node/lib/python3.10/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[1;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/anaconda3/envs/node/lib/python3.10/site-packages/torchvision/transforms/transforms.py:135\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m    128\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[0;32m~/anaconda3/envs/node/lib/python3.10/site-packages/torchvision/transforms/functional.py:163\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39m# handle PIL Image\u001b[39;00m\n\u001b[1;32m    162\u001b[0m mode_to_nptype \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mI\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mint32, \u001b[39m\"\u001b[39m\u001b[39mI;16\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mint16, \u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mfloat32}\n\u001b[0;32m--> 163\u001b[0m img \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(np\u001b[39m.\u001b[39;49marray(pic, mode_to_nptype\u001b[39m.\u001b[39;49mget(pic\u001b[39m.\u001b[39;49mmode, np\u001b[39m.\u001b[39;49muint8), copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\n\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m pic\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    166\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m \u001b[39m*\u001b[39m img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "\n",
    "EPOCH = 10\n",
    "LR = 1e-3\n",
    "accum_loss = 0\n",
    "train_loss_arr = []\n",
    "test_loss_arr = []\n",
    "accum_acc = 0\n",
    "acc_arr = []\n",
    "\n",
    "# 모델 초기화 및 손실 함수, 최적화 알고리즘 설정\n",
    "# model = ResNet(ResidualBlock, num_classes=10).to(device)\n",
    "model.to(device) # summary 함수는 모델을 cpu로 꺼내버림\n",
    "loss_func = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# 모델 학습\n",
    "for epoch in range(EPOCH):\n",
    "    model.train()\n",
    "    with tqdm(total=len(train_loader), desc='Train') as pbar:\n",
    "        for x,y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            train_output = model(x.to(device))\n",
    "            train_loss = loss_func(train_output, y.to(device))\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.update(1)\n",
    "            accum_loss += train_loss.cpu().item()\n",
    "    cur_train_loss = accum_loss/len(train_loader) # (아마도) loss는 미니배치 한 개에 들어있는 데이터 개수 만큼의 loss를 의미할 것임.\n",
    "    train_loss_arr.append(cur_train_loss)\n",
    "    accum_loss = 0\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(test_loader), desc='Evaluation') as pbar:\n",
    "            for x,y in test_loader:\n",
    "                test_output = model(x.to(device))\n",
    "                test_loss = loss_func(test_output, y.to(device))\n",
    "                accum_loss += test_loss.cpu().item()\n",
    "                max_prob, pred_idx = torch.max(test_output.data, 1)\n",
    "                accum_acc += (pred_idx.cpu() == y).sum().item()\n",
    "                pbar.update(1)\n",
    "    cur_test_loss = accum_loss/len(test_loader)\n",
    "    test_loss_arr.append(cur_test_loss)\n",
    "    cur_acc = 100*accum_acc/len(test_loader.dataset)\n",
    "    acc_arr.append(cur_acc)\n",
    "    accum_loss = 0\n",
    "    accum_acc = 0\n",
    "    print(\"Epoch [{}/{}] Train_Loss: {:.4f}, Test_Loss: {:.4f}, Test_acc: {:.2f}\".format(epoch+1, EPOCH, cur_train_loss,cur_test_loss, cur_acc))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "node",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e0784ea833aae75f0caebf3e5c363487ed4aa83a6f0d1a675110c94f215f240"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
